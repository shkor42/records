Сделать через n8n работает, но очень долго. Я слышал, что если просто альтернативу брать, про записи, про историю с микрофоном или аудио закидывать, в целом, про пользование. Когда переводчики онлайн получают слишком большие голосовые файлы, слишком длинная запись, они часто начинают переводить на чанки. Грубо говоря, я подряд ковырю 40 секунд, и за это время это уже 3 чанка каких-нибудь. И первые два из них уже закинуты как аудиофайлы процесса, а третий еще записывается. И вот так решается вопрос с тем, что кажется, как будто это в реальном времени. По факту, да, сначала запись прошла, а вот эта рожка переводится в текст. Еще раз, я не понял. Скажи еще раз, что ты хотел сказать, я не понял. Я хотел сказать то, что историю тем в реальном времени будет получать бот информацию, ну как с микрофона, или закидывать в него аудиофайл, может решаться тем, что длинный какой-то звонок, вот наш звонок, не знаю, 40 минут. Не надо ждать, пока он закончится, отправлять ему аудио, а надо сделать так, чтобы этот звонок делился параллельно на чанке. Прошла минута, запись прекратилась автоматически самим ботом, он закидывает ее в процессе, запустил следующую минуту по записи. И в итоге, ну, типа, всегда с каким-то очень небольшим лагом будет бот понимать всю информацию, не надо будет ждать все 40 минут, я про это. Да, ну так мы же, в принципе, только что это обсудили, что нужно понять размер чанки, не знаю, там, минута может быть коротковата, 10 минут, мне кажется. Это такое near real-time решение. Типа, real-time решение, я вот попробовал тоже запрототипировать, оно значительно сложнее получается. Ну, типа, near real-time решение мы можем сейчас сделать. Вообще, near real-time решение я уже сделал. Вот, конкретно, пожалуйста, можете пробовать. Ладно, я думаю, что это такой кусочек для Telegram, это чисто наш кейс. Он, по-моему, вообще Telegram не пользуется, типа, Роберт, поэтому там надо просто что-то типа VoiceMod в OpenUI. Ну, так давайте сделаем эту веб-прилагу. Я бы просто сразу делал с групповым чатом, но, может, не обязательно, может, иногда и на одном окей будет. Просто вот для веб-прилаги как будто бы... Для веб-прилаги. Слушайте, может быть, тогда попробовать вообще от веба немножко уйти, просто под макой сделать решение, которое будет капчерить input-output, типа, этот voice. Ну, можно локальную вообще штуку сделать. Ну, типа, просто нам надо прилага, которая будет как веб-прилага, ну, типа, просто нам надо прилага, которая будет как... Как там эта штука называется? Как OBS, короче, будет, типа, захватывать канал, ну, типа, этого, блядь, input-output, да, и его сразу кидать на процессинг. Ну, то есть там, ну, типа, чанкование какой-то секунд по 10, по 15, ну, типа, собирать какой-то контекст, ну, в принципе, дальше уже pipeline. То есть, в принципе, это закрывает момент с тем, что у каждого есть свой собственный помощник, это закрывает нам момент с тем, что у каждого там, ну, типа, все они могут работать на одном серваке, но там с разными permissions, условно, с разным контекстом. Вот, и закрывает момент с тем, что нам не надо, типа, встраиваться во все опихи, мы просто можем с макоси, типа, запирать сразу весь звук. Ну, и это такая больше, ну, мне кажется, типа, шире история просто, потому что нам просто не надо интегрироваться, типа, во много-много-много, типа, разных штук, а у тебя вот есть твой личный там помощник, можем… Аппы для макоси пишут. Ну, короче, есть фреймворки, на которых можно писать, типа, локальное приложение. Ну, типа, макоси-приложение на реакте. Можно, в принципе, такое попробовать. Не, ну это понятно, потому что там куча электронных… Во, электрон, электрон, да. Так, я бы все-таки задержался на use case пока что. А он не пользуется телеграмом вообще? Нет. А как ты с ним общаешься? Слаг. Ну, типа, слаг, зум, гугл мид, такие вот истории. Мне очень много ребят из Америки говорило о том, что телеграм для любого находится у них, ну, типа, в такой статус, то есть, ну, такого криптического приложения. Да, и чтобы… Никто там не работает. Чтобы жена не запалила? Ну, типа, ну, короче, я к тому, что это такое приложение максимально не для работы. То есть, там, ну, как будто у них даже к ватсапу лучше отношение, чем к телеграму. Телеграм – это такая херня максимально неформальная, не рабочая. Но, с другой стороны, мы личную штуку делаем не только там для рабочих. Так, я предлагаю, смотрите, тогда все-таки делаем такой флоу. У нас есть бот, который регулярно, ну, похер когда, типа, near real-time. Берем такую концепцию, near real-time. Делаем такую штуку, типа, что он, он, короче, парсит транскрипт. В транскрипте он определяет команды, которые были ему заданы. То есть, тут нужно понять, есть ли у нас некоторые варианты. Мы либо говорим, что вообще свободный набор команд. Ну, типа, либо тогда он, типа, вообще может выполнять любые команды. Но там, как бы, меньше будет точности. Либо мы говорим, смотрите, у нас есть список каких-то команд, которые, типа, можно, он может получать. И там начинается с этого списка какого-то дефолтного. Либо вообще пустой, с единственной командой. Это создать команду. Вот. И, собственно, в таком случае нам нужно вот что сделать. Нужно понять, понять этот список команд. Ну, типа, и с ним как-то, с ним как-то, короче, выйти на уровень, когда у нас эти команды будут экзамьютироваться прям очень хорошо. То есть, либо у нас, ну, еще раз, короче, подход. Либо мы сделаем этот список команд и, типа, даем возможность их тюнить. То есть, список команд у нас больше контроля. Либо мы вообще даем такой более свободный флоу. Ты говоришь, ну, типа, в принципе, любую команду он может заэкзагютить. Но я, как бы, могу практически точно сказать, что он меняет, ладно, такое ощущение, точно не могу сказать, но у меня такое ощущение, что он будет тогда херовенько, херовенько работать. То есть, он будет такой, как это... Он сто процентов будет херово работать. Это, ну, типа, даже не вопрос этого утверждения. Если просто сказать, типа, он может делать абсолютно сейчас все, то есть, тогда там просто будет какая-то же внутри базовая нейронка, к которой мы будем обращаться. Ну, и, типа, уровень будет такой же, как сейчас, но базовая нейронка, которая, ну, не наточена, не на каких-то специальных фронтах, не обучена на каких-то специальных фронтах. Ну, да, то есть, вот, скорее всего, сейчас такой уровень вот у этого кода, который я скинул. То есть, он примерно так же сработает, потому что он не... Ну, короче, он не... Он не то чтобы заточен на... Как это? На эти... Как их? Короче, не заточен на какие-то конкретные команды. Он, типа, любые команды экзекьютит. Ну, в принципе, он это делает, но, как бы, уровень консистентности такой, типа, средний, я бы сказал. Вот, если так вот... ...говорить. Ну, короче, по факту нам надо, типа, собрать какой-то список, ну, там, типа, первые условно 20, 30, 40, 50 команд. Да, пускай, ну, мы их изначально, типа, ну, там, сделаем сами. Потом нам надо какой-то автогенератор. Возможно, типа, пускай он идет, там, сначала в одну модельку, потом в другую, потом в третью. Собирает какой-то полноценный промпт. Ну, вообще, типа, я бы, конечно, хотел, чтобы бот мог работать в любых сценариях, чтобы можно было подключать туда MCP любые. Ну, собственно, типа, как у всех крутых человек. Да, это чуть другая штука, ну, типа, ну, вообще, как бы, я бы просто делал... Начально, понимаешь, типа, нам нужна какая-то консистентность. Потому что сейчас пока нету таких вот прям мощных помощников ни у кого, понимаешь, которые там могут прям, ну, сделать такие открытые задачи. И мне кажется, в этом как раз-таки проблема. То есть, ты, если даешь ему какой-то супероткрытый инструмент, во-первых, многим, как бы, не хочется давать слишком большой контроль. Например, дашь боту, пиздец, типа, дашь ему доступ к кошельку какому-нибудь, понимаешь. Ну, типа, есть очень высокий шанс, что он просто нахер спустит все эти бабки. Поэтому, типа, явно нужен какой-то такой более высокий уровень контроля. Не, ну, для кошелька тут может быть просто история с тем, что какое-то подтверждение перед, да, типа, экзекьютом каких-то команд, да, таких, типа, sensitive. Да, да, да. Я, кстати, думаю, что в этом-то и фишка. Что, если мы делаем эту вот систему с помощью command and queries, то есть, типа, вот как SQL, то, в принципе, у нас для некоторых команд мы можем делать отдельную настройку. Типа, там, уровень уверенности, когда он может запускать эту команду. А для некоторых команд вообще, типа, обязательно подтверждение от клиента. И, типа, у тебя просто приходит нотификация, типа, бот хочет запустить такую команду, и ты подтверждаешь. Ну, типа, если это какие-то высокочувствительные команды. Если ты ставишь что-то вообще автоматом, что-то автоматом, если высокий уровень уверенности, понимаешь такой уровень настройки. И этот уровень настройки тебе бот тоже помогает настроить. Ну, да, в принципе, то же самое, что сейчас, типа, в курсоре сделано, например, да, когда у тебя, типа, стоит агентик мод, вот этот вот авто. Но при этом, когда он хочет, там, что-то запустить у тебя, какой-то код, он тебя спрашивает, типа, там, уверен ли ты, что это нормально. Я хотел сказать то, что надо помнить. Ну, типа, просто многие пользователи всей кейсы могут решаться лучше не полностью, если AI будет какой-то их делать, а если AI будет вызывать какие-то инструменты, которые это делают, ну, банально, например, калькулятор. Типа, нахера использовать, ну, не знаю, какую-то нейросетку, которая может там ошибиться, если она просто может вызвать прилавку к калькулятору у нас, там, самую простую, посчитать что-то и сказать ему. Или там тоже вопрос, мы там про время говорили, да, там засекать, что-то еще, ну, что-то. Ну, то есть много будет каких-то вещей, где мы просто должны будем в use case заложить то, что наш код какой-то срабатывает, или там сама нейросетка вызывает какой-то инструмент, и с этого инструмента что-то делает. И с банковскими данными, с финансовыми данными, мне кажется, там, 100%, ну, там, грубо говоря, не знаю, есть какие-то сейчас финансовые решения, и потенциально может быть какой-то матч с ними, и, ну, нейросетка не сама будет что-то делать там финансовое, а отправлять там какую-то команду в эти решения. Но в любом случае, там, подтверждение может происходить в самих этих решениях. Ну, типа, аля, там, приведет тебе в какой-то их аналог киньки банковского прилаге, то, что, типа, да, вот, согласен ли ты там оплатить что-то там. И там человек подтверждает, он не говорит там голосом нашему джарвису, да, я подтверждаю, что надо перевести. Да, я об этом и говорю. Просто и в этой связи как раз лучше разрабатывать просто набор каких-то функций, действий, которые он может делать, но не давать общий открытый инструмент, потому что в общем открытом инструменте этого не будет. Или будет всегда возможность того, что, ну, в отдельном кейсе бот сделает это не оптимальным образом с вызовом каких-то других инструментов, а просто, ну, каким-то другим, тем самым. Ну, короче, как будто бы, типа, все у нас переходит к тому, что нам надо определить какой-то список сценариев изначальных, по которым этот бот будет работать. Их, типа, условно сделать в полуручном режиме, типа, потюнить, чтобы они хорошо работали. И, ну, вот эти вот знания, которые мы обретем, когда их сделаем, мы их впилим в автоматический генератор вот таких вот тулов. Да, в принципе, эти тулы могут распространяться, типа, на открытом доступе как-то, как workflow в n8n. То есть, есть просто какой-то public marketplace этих тулов для этого бота. И, ну, вот как список MCP-шек. Ну, да. Sounds good. Вот, ну, и я бы тогда, ну, типа, если мы идем вот по этому Jarvis-like треку, то как будто бы приложение нативное под МакОсь, оно нам надо. Да. Чтобы все это слушать. Ну, хотя, в принципе, с другой стороны, так же это можно сделать пока что в вебе, как первую версию. Ну, просто вот вебовское приложение, оно как будто бы, типа, код сможет ранить только на серваке. А нативное приложение под МакОсь, по идее, сможет и браузер твой подконтролить, как ChargePT оператор, и что-то у тебя локально вызвать, и по каким-то там твоим файлам локально посмотреть. Ну, да. Локально лучше. Локально лучше. Да. Ну, че, туда нам надо электронапа. Получается, Симбиот, запиши, что нам надо электронапа. Четко. Четко. Да.